{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data"
      ],
      "metadata": {
        "id": "0D85rnQ1V6jW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "uc2GYRZzKyzh",
        "outputId": "70d86d6c-b4d8-4d81-8b33-2b35de886be7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-27 04:29:49--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.180.207, 172.253.122.207, 172.253.63.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.180.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   258MB/s    in 0.3s    \n",
            "\n",
            "2024-11-27 04:29:49 (258 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT36rxRVmHZk",
        "outputId": "a7adec96-5b1e-4886-c667-c6c91e83eb4b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/cats_and_dogs_filtered/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the Data into arrays"
      ],
      "metadata": {
        "id": "xgEKdtTjV8Sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "cats_dir = os.path.join(train_dir + \"/cats\")\n",
        "dogs_dir = os.path.join(train_dir + \"/dogs\")\n",
        "i = 0\n",
        "\n",
        "NUMBER_OF_EXAMPLES = 1000\n",
        "x_train = []\n",
        "y_train = []\n",
        "while i < NUMBER_OF_EXAMPLES:\n",
        "  if i % 2 == 0:\n",
        "    im = Image.open(os.path.join(cats_dir, os.listdir(cats_dir)[i])).convert(\"RGB\")\n",
        "    im_resized = im.resize((150, 150))\n",
        "    x_train.append(np.array(im_resized))\n",
        "    y_train.append(1)\n",
        "  else:\n",
        "    im = Image.open(os.path.join(dogs_dir, os.listdir(dogs_dir)[i])).convert(\"RGB\")\n",
        "    im_resized = im.resize((150, 150))\n",
        "    x_train.append(np.array(im_resized))\n",
        "    y_train.append(0)\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "QOhkfFT1K4o1"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "cats_dir = os.path.join(validation_dir + \"/cats\")\n",
        "dogs_dir = os.path.join(validation_dir + \"/dogs\")\n",
        "i = 0\n",
        "NUMBER_OF_EXAMPLES = 500\n",
        "x_test = []\n",
        "y_test = []\n",
        "while i < NUMBER_OF_EXAMPLES:\n",
        "  if i % 2 == 0:\n",
        "    im = Image.open(os.path.join(cats_dir, os.listdir(cats_dir)[i])).convert(\"RGB\")\n",
        "    im_resized = im.resize((150, 150))\n",
        "    x_test.append(np.array(im_resized))\n",
        "    y_test.append(1)\n",
        "  else:\n",
        "    im = Image.open(os.path.join(dogs_dir, os.listdir(dogs_dir)[i])).convert(\"RGB\")\n",
        "    im_resized = im.resize((150, 150))\n",
        "    x_test.append(np.array(im_resized))\n",
        "    y_test.append(0)\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "r1Y1PhsBtS-4"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beginning to define the model (this is where you come in, I loaded the pretrained model for you)"
      ],
      "metadata": {
        "id": "t7R64c0tV-zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "pretrained_model = tf.keras.applications.ResNet50(\n",
        "    include_top=False,\n",
        "    input_shape=(150, 150, 3),\n",
        "    pooling='avg', classes=2,\n",
        "    weights='imagenet')\n",
        "for layer in pretrained_model.layers:\n",
        "  layer.trainable=False\n",
        "\n",
        "model.add(pretrained_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu')) #512 hidden neurons completely arbitrary\n",
        "model.add(Dense(2, activation='softmax')) # 2 neurons to categorize\n"
      ],
      "metadata": {
        "id": "7zGbGnknK6uG"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "FLsqoOe6rYK6",
        "outputId": "bb54644c-241e-4f87-e429-df041e88e264"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │      \u001b[38;5;34m23,587,712\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,049,088\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │           \u001b[38;5;34m1,026\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,637,826\u001b[0m (93.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,637,826</span> (93.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,050,114\u001b[0m (4.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,114</span> (4.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "M5CJd1rPrskW"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_train=np.array(x_train)\n",
        "x_test=np.array(x_test)\n",
        "\n",
        "x_train = x_train.reshape(-1, 150, 150, 3)\n",
        "x_test = x_test.reshape(-1, 150, 150, 3)\n",
        "epochs = 10\n",
        "# Then train\n",
        "history = model.fit(\n",
        "    np.array(x_train), np.array(y_train),\n",
        "    validation_data=(np.array(x_test), np.array(y_test)),\n",
        "    epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61F3v_EGu5pj",
        "outputId": "8dcf8369-b426-424b-ed7e-752d8dad18a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m20/32\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 3s/step - accuracy: 0.5351 - loss: 0.7180"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "image = cv2.imread(\"cat.jpg\")\n",
        "image_resized = cv2.resize(image, (150, 150))\n",
        "image= np.expand_dims(image_resized, axis=0)\n",
        "pred= model.predict(image)\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "qmwf5RHm51EE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}